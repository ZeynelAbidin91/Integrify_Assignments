{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.7 : What are normal equations? Is it the same as least squares? Explain. You may refer to this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal equations (OLS-Ordinary least squares) is a method which is used to determine the weight vector(coefficients) analytically when we want find the linear regression of a dataset. It's one-step method as opposed to gradient-descent.\n",
    "\n",
    "Suppose we have below equation:\n",
    "\\begin{align}\n",
    "Xw=y\n",
    "\\end{align}\n",
    "Normal equations is basically used to find best possible w (coefficients - weight vector) analytically.\n",
    "\n",
    "X : Features for each example\n",
    "y : Actual output values for each examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Least Squares:\n",
    "\n",
    "To try to minimize the error \n",
    "\\begin{align}\n",
    "e =  y - Xw \n",
    "\\\\||e||^2 = ||y - Xw||^2\n",
    "\\\\w = (X^TX)^{-1}X^Ty \n",
    "\\end{align}\n",
    "\n",
    "Normal Equations:\n",
    "\n",
    "Using Linear algebra \n",
    "\\begin{align}\n",
    "\\\\Ax = b\n",
    "\\\\When we multiply both side by A^T to find best x'\n",
    "\\\\A^TAx' = A^Tb\n",
    "\\end{align}\n",
    "\n",
    "'Least squares' and 'Normal Equations' methods have the same approach to find same thing in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.8 Is feature scaling needed for linear regression when using gradient descent?  Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea with the feature scaling is making sure features are on a similar scale. When using gradient descent we would want to apply feature scaling so gradient descent can converge minimum point more guickly and more concretely on cost function. The gradient Descent can find direct path to find global minimum if the contours are like more circles in the cost function rather than applying gradient descent on skew contours. Otherwise on the cost function gradients may end up taking a long time before it converges finally global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.9 Write out the MLE approach for logistic regression. How is this related to the binary cross-entropy? You can use this reference to answer this question. Video Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
