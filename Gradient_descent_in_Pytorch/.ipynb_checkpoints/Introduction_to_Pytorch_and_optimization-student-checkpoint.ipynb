{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic Commands, Helper Functions and Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from IPython.display import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "#%autoreload 2\n",
    "#\n",
    "## Easy to read version\n",
    "#%system date\n",
    "#\n",
    "## Shorthand with \"!!\" instead of \"%system\" works equally well\n",
    "#!!date\n",
    "#!!ls\n",
    "#\n",
    "## Outputs a list of all interactive variables in your environment\n",
    "#%who_ls\n",
    "#\n",
    "## Reduces the output to interactive variables of type \"function\"\n",
    "#%who_ls function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipQhApGJfTxe"
   },
   "source": [
    "\n",
    "What is and WHY Use PyTorch?\n",
    "================\n",
    "\n",
    "Itâ€™s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  **An extensible alternative for NumPy harnessing the power of GPUs**\n",
    "-  a **deep learning research platform that provides maximum flexibility\n",
    "   and speed**\n",
    "\n",
    "Getting Started\n",
    "----------------------------\n",
    "\n",
    "To get started, please open the [documentation get-started](https://pytorch.org/get-started/locally/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Tensorflow 1. Pytorch advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read the following questions and try to guess the answers.\n",
    "<ol>\n",
    "  <li>What language has Torch been written in?</li>\n",
    "  <li>Where does the name PyTorch come from?</li>\n",
    "   <li> What  <a href=\"https://en.wikipedia.org/wiki/Programming_paradigm\">programming paradigm </a>  is PyTorch built upon? Choose between declarative, procedural, imperative and functional. </li>\n",
    "    <li> What is the main difference between Tensorflow1 and PyTorch in terms of runtime execution? </li>\n",
    "    <li> Why graph dynamic execution in Pytorch better than static graph execution used e.g. in Tensorflow? </li>\n",
    "</ol>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gk9bQX7fTxh"
   },
   "source": [
    "Now please watch the [video](https://www.youtube.com/watch?v=nbJ-2G2GXL0) and compare your prior guesses to the answers given in the video. Write down what you learned.\n",
    "\n",
    ":)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Learn Pytorch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every new learning would be made so much easier by gathering motivation for it. This is based on the famous <a href=\"https://hoishampark.wordpress.com/2017/04/14/motivation-hacker-a-book-report/\">MEVID </a>  formula\n",
    "Now you might be wondering that PyTorch is a cool and versatile imperative programming based deep learning framework,in which the computations are handled dynamically. \n",
    "\n",
    "But..\n",
    "\n",
    "**Why should I learn it ?**\n",
    "\n",
    "**Simple answer : Best both for short and long research projects!**\n",
    "\n",
    "But there is much more!\n",
    "\n",
    "[This article will give you the motivation to learn PyTorch](https://www.analyticsindiamag.com/9-reasons-why-pytorch-will-become-your-favourite-deep-learning-tool/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up CUDA and Pytorch\n",
    "\n",
    "## Setting Up CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good practice to develop the habit of having the right tools for each job.\n",
    "- If you have a separate NVIDIA GPU in your disposition, PyTorch should be used with CUDA to speed up computation. In this case, please [install CUDA](https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html)\n",
    "\n",
    "\n",
    "- Otherwise you may use Google Colaboratory through which you can use Tesla K80 GPU for free! Please see [this post](https://medium.com/@ml_kid/google-colab-notebook-with-pytorch-v1-0-stable-lesson-9-46433881da05) on how to set up Google Colaboratory with Tesla. The first commands needed to run are specified in [this notebook](https://colab.research.google.com/drive/18R3Rz639Fa4ByFwzLrY5LmD8t3Ee5IUR) . You can always run any Jupyter Notebook on Google Colaboratory. To do this, just upload the notebook to Google Colaboratory while inside Colaboratory.\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "  Warning: You may run into authentication issues while trying to persist your variables on Colaboratory, especially after you wish to keep your session open to re-run it later. The free instance is periodically turned off and re-authentication may be required. Otherwise Colaboratory might complain about missing files (this may be because the session was disconnected at some point).\n",
    "</div>\n",
    "\n",
    "\n",
    "- Since the majority of this course is not GPU-intensive, you may also run the Notebooks on your CPU. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Pytorch runtime uses CPU\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# Print out your first tensor. Update the code with one line to print out your first tensor object\n",
    "cuda0 = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Your Pytorch runtime uses GPU\")\n",
    "    cuda0 = torch.device('cuda:0')\n",
    "    first_tensor_on_cuda = torch.ones([2, 4], dtype=torch.int32, device=cuda0)\n",
    "    print(first_tensor_on_cuda)\n",
    "else :\n",
    "    print(\"Your Pytorch runtime uses CPU\")\n",
    "    first_tensor_on_cpu = torch.ones([2, 4], dtype=torch.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "IF you wish to practice using CUDA, please install   <a href=\" https://wiki.tiker.net/PyCuda/Installation\"> PyCuda.</a>\n",
    "\n",
    "Why you should use  <a href=\"https://devtalk.nvidia.com/default/topic/573367/pucuda-pros-and-cons/\">PyCuda instead of C</a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9a80ff593860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Get Id of default device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pycuda.driver as cuda\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "\n",
    "cuda.Device(0).name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setting Up Tensorboard -- Visualization Platform (Works on Tensorflow, Pytorch, Keras,...)\n",
    "It's always good to see the visual outputs of the code you are writing, and  especially in machine learning.Typically machine learning engineer would plot the underlying neural network as a graph, training error of the network during training time, visual outputs of the hidden layers.\n",
    "That is why we give two examples of platforms that have native integration with PyTorch.\n",
    "\n",
    "Popular Visualization platforms for Pytorch are [Visdom](https://github.com/facebookresearch/visdom) and [TensorboardX](https://github.com/lanpa/tensorboardX). According to the discussion on [reddit](https://www.reddit.com/r/MachineLearning/comments/8ej2j4/d_facebook_visdom_vs_google_tensorboard/) ,people use both, both for different purposes.\n",
    "\n",
    "[How to use TensorboardX](http://www.erogol.com/use-tensorboard-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  Followingly, the commands ran assume that you have a  Conda Virtualenv called dl created , and we are going to install the packages there.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: tensorboard: not found\r\n"
     ]
    }
   ],
   "source": [
    "#!yes | conda install -n dl -c conda-forge tensorboardx\n",
    "# start Tensorboard instance\n",
    "#! yes |conda install -n dl -c conda-forge tensorflow \n",
    "\n",
    "# ! yes |conda install -n dl -c conda-forge tensorboard \n",
    "log_path = './runs/gd/'\n",
    "!tensorboard --logdir log_path\n",
    "# to add more objects to Tensorboard, please read the manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Structures in PyTorch. Tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Definition and Some Important Properties\n",
    "### Definition of a n-th Order Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Definition of a Tensor** :\n",
    "An **n-th Order Tensor** is a n-dimensional array of numbers.\n",
    "In this definition, each dimension is considered to be  independent of each other.\n",
    "\n",
    "By *practical* we mean that this is the definition that is used in computer programming and software libraries that are used in the industry and practice.\n",
    "\n",
    "The word *tensor* comes from physics and was initially used to describe the **tension** on materials. Since it was necessary to  describe the tension on each face of a solid body, a simple 2D matrix was enough, since the first dimension could be used to denote the normal direction of the face and the 2nd dimension the direction of the tension. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Comparison to mathematical definition of tensor</h4><p>\n",
    "This definition differs significantly from the mathematically rigorous definition of a tensor, in which case a n=(p+q)-order or (p,q)-tensor is defined as multilinear mapping that is linear with respect to each of its arguments (p vectors and q  co-vectors or differential forms) that retains certain invariants under a coordinate transformation. Thus, in mathematics, only those multilinear mappings are tensors that retain its invariants.\n",
    "    </p></div>\n",
    "\n",
    "**Henceforth we are only going to use the practical definition of a tensor.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Interpretation in Programming Context\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Tensors are similar to Python's NumPyâ€™s ndarrays but they have the additional property that\n",
    "Tensor data structure can be scaled up horizontally and thus can also be used on a GPU to accelerate computing. \n",
    "</div>\n",
    "\n",
    "[Tensor](https://en.wikipedia.org/wiki/Tensor) is also the **basic data structural unit in PyTorch**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2D-matrix is an example of a 2-nd order tensor, but a specific example of a n-th order **tensor**, which in general has  **n** independent components. Consider the following example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image(\"assets/img/tensor.jpg\")\n",
    "# Source : https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwirxuj998nhAhUqtYsKHfFbAhUQjRx6BAgBEAU&url=https%3A%2F%2Fwww.slideshare.net%2FBertonEarnshaw%2Fa-brief-survey-of-tensors&psig=AOvVaw0tULmnEC2-vr346HuYGbdQ&ust=1555137171132510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that to represent a single pixel on an image, we need 3 independent components:\n",
    "\n",
    "    > 1-st component denotes the x-location (width-location)\n",
    "    > 2-nd component denotes the y-location (height-location)\n",
    "    > 3-rd component denotes the color channel (R,G,B) since any colour displayed on a computer screen is formed from the 3x 8-bit (R,G,B)-triplet each having values between 0 and 255.\n",
    "    \n",
    "Thus we can think of a cat image on a computer screen  of as a discrete rectangular prism or a multidimensional array of numbers as shown on the above image. This rectangular n-dimensional array of numbers is called an **n-th order tensor**.\n",
    "\n",
    "This conceptually natural connection between image and a tensor is very important since this forms the basis why GPUs are used in machine learning.\n",
    "GPU is a graphical processing unit, usually containing many computational cores (many more than CPU, central processing unit) and they are optimized for operations that are done with images, which we now know to be n-dimensional tensors. \n",
    "\n",
    "*Thus it is believable why GPUs should be suitable for doing computations with tensors or high-dimensional data.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations with Tensors in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88P6CttefTxo"
   },
   "source": [
    "Followingly, let's see how to form tensors in PyTorch.\n",
    "Tensors can be created from both Python base class data (e.g. list of lists) as well as from Numpy array data.\n",
    "To get started, please check the [documentation](https://pytorch.org/docs/stable/tensors.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_from_2d_list = torch.tensor([[1., -1.], [1., -1.]])\n",
    "\n",
    "\n",
    "# Print the tensor object created from Python List \n",
    "# Write your code here ...\n",
    "print(tensor_from_2d_list)\n",
    "\n",
    "\n",
    "tensor_from_np_array = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "\n",
    "\n",
    "# Print the tensor object created from Python Numpy array \n",
    "# Write your code here ...\n",
    "print(tensor_from_np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are some common ways to create a [Tensor](#Definition-of-a-n-th-Order-Tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3371,  0.2020,  0.0969,  0.8152, -1.0316,  1.2447, -0.7170, -0.2312,\n",
      "          1.5161,  0.1880],\n",
      "        [-0.5919, -0.7649, -1.4935, -0.1142,  0.2898, -0.6985,  0.4627,  0.8880,\n",
      "          1.5742,  2.3387],\n",
      "        [ 0.2728, -0.9360,  0.5725, -0.6141, -0.3691, -0.0935,  0.0426, -0.1804,\n",
      "         -0.7314, -0.2395],\n",
      "        [ 0.8567, -1.2145, -0.8619, -1.3146,  1.7339,  1.2548, -0.9337, -0.3377,\n",
      "         -1.5949, -0.4954],\n",
      "        [-0.7227, -0.2879, -0.0755,  0.9883,  0.7905,  1.5976,  0.3013,  0.0902,\n",
      "          0.7360, -0.5025],\n",
      "        [-0.1258, -0.1951,  0.4236, -0.0072,  1.7806,  0.9225,  0.8129,  1.2064,\n",
      "          0.6610, -0.3056],\n",
      "        [ 1.4317,  1.4301, -1.6285,  1.1117,  0.9528, -0.4513,  0.9715,  0.6984,\n",
      "         -0.0205,  0.3752],\n",
      "        [-0.4226,  0.9035,  0.2991, -0.8611, -2.1557,  1.1949, -0.3645,  0.6090,\n",
      "         -1.2770, -0.5979],\n",
      "        [-1.0308,  1.0476,  0.2284, -0.3256, -0.7111,  0.5080,  1.1272, -0.6360,\n",
      "         -0.7461,  0.4849],\n",
      "        [ 1.1858,  1.3492, -1.1615,  0.4350, -0.0725,  0.8490,  0.1018,  0.4045,\n",
      "          0.0359,  0.2372]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(2,2)\n",
    "b = torch.zeros(2, 2, dtype=torch.long)\n",
    "c = torch.rand(5, 5)\n",
    "\n",
    "d = a.new_ones(10, 10, dtype=torch.double)\n",
    "e = torch.randn_like(d, dtype=torch.float) \n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. What is the difference between tensors a and b?\n",
    "Q.1: b contains zeros in shape 2x2, a contains only not assigned values as empty\n",
    "2. What about d and e? When would you use randn_like function?\n",
    "Q.2: d contains ones in shape 10x10, e contains randon floats in shape of d.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followingly see the available methods on the tensor object by clicking x. and TAB\n",
    "To see the DOCSTRING of the specific function, select or type the chosen function and then click SHIFT+TAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image(\"assets/img/tabcomplete.png\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tensor to Numpy array conversion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.arange(16)\n",
    "test_tensor = torch.from_numpy(test_array)\n",
    "test_array2 = test_tensor.numpy()\n",
    "print(f\"The type of test_array is, {type(test_array)}\\n\")\n",
    "print(f\"The type of test_tensor is, {type(test_tensor)}\\n\")\n",
    "print(f\"Are the shapes of the objects are equal? : {test_array.shape == test_tensor.shape}\\n\")\n",
    "print(f\"After converting the tensor back to Numpy array, is the initial array equivalent to the converted array?\")\n",
    "print(f\"{all(test_array == test_array2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Reshaping : View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) \n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View is a similar function to Numpy's reshape. What is the meaning of parameter -1?\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>-1 means that if we don't know what is the dimensionality count in a particular dimension, leave it unspecified by writing  -1. In this case, the number of samples in this dimension is inferred from the other dimensions, e.g. if you have a 4 x 4 array x and you use x.view(-1,8), then -1 stands for 2.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors on CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural representation of many types of data is a in a form of a high-dimensional array. \n",
    "GPUâ€™s have always been good for machine learning. GPU cores were originally designed for physics and graphics computation, which involves matrix operations. General computing tasks do not require lots of matrix operations, so CPUâ€™s are much slower at these. Physics and graphics are also far easier to parallelise than general computing tasks, leading to the high core count.\n",
    "\n",
    "Due to the matrix heavy nature of machine learning (neural nets), GPUâ€™s were a great fit.\n",
    "Next we are going to define the CUDA device, if available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your system doesn't have CUDA\n"
     ]
    }
   ],
   "source": [
    "# create_formatted_var(\"device\")\n",
    "# We will use  \n",
    "if cuda0 is not None:\n",
    "    device = cuda0\n",
    "    print(\"Cuda device cuda0 loaded before\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "else :\n",
    "    print(\"Your system doesn't have CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a data structure object directly to GPU, please use the ``device`` argument.\n",
    "If the data object was created before in a memory location other than GPU-memory, use the ``tensorobject.to(device)`` syntax to transfer the data structure from memory to GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cuda0 is not None:\n",
    "    x = torch.ones(3,device=\"cuda\")\n",
    "else :\n",
    "    cuda0 = 'cpu'\n",
    "    x = torch.ones(3,device=cuda0)\n",
    "x.device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Transformations in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition of Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before learning any transformations, it would be useful to know how quickly a  given transformation is going to run. For that purpose, please feel free to make use of the iPython Magic Command %%timeit , that creates a loop and evaluations its running time in Jupyter Notebook.\n",
    "\n",
    "Take 5 minutes to go over the next TOP 5 Magic commands in Jupyter, it might you save a lot of time later\n",
    "\n",
    "[TOP 5 Jupyter Magic commands](https://towardsdatascience.com/the-top-5-magic-commands-for-jupyter-notebooks-2bf0c5ae4bb8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tt33-AiWfTyS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 4, 4]) tensor([5, 2, 1])\n",
      "CPU times: user 1.13 ms, sys: 219 Âµs, total: 1.35 ms\n",
      "Wall time: 7.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = torch.tensor([1,2,3],device=cuda0)\n",
    "y = torch.tensor([5,2,1],device=cuda0)\n",
    "\n",
    "# way 1 :\n",
    "result = torch.add(x,y)\n",
    "print(result,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ja3Wtk9TfTyZ"
   },
   "source": [
    "Addition: providing an output tensor as argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2vFR-eWfTyh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "#y.add_(x)\n",
    "x = torch.tensor([1,2,3],device=cuda0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBpJnar4fTym"
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PnD23OjfTyn"
   },
   "source": [
    "### Homework Exercise on Tensor Adding Error Handling:\n",
    "\n",
    "Write a function ``try_adding_different_locations`` that has 4 input arguments:\n",
    "- x : This is the input tensor, it should be passed as a default argument, that is 2nd-order 3x3 tensor of ones, created on CPU\n",
    "- device: This should be passed as a default argument, and it is the CUDA device available on your system\n",
    "- notbtoh : bool. This argument should be passed as boolean with True as default value\n",
    "- output_type : string with default_value \"cpu\"\n",
    "\n",
    "TASK: **The function should probe out all combinations in which the tensor addition should or should not work.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_adding_different_locations(x = A, device = 'CUDA', notbtoh = True, output _type = 'cpu':\n",
    "                                   A = \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication on Tensor Objects using mm\n",
    "\n",
    "From linear algebra course at school, you may remember the concept of matrix multiplication.\n",
    "Since  image is a tensor, and tensor is a generalization of a matrix, matrix multiplication also works for tensors.\n",
    "\n",
    "In a course taught in universities, called **Tensor Calculus**, the defined operations between tensors include tensor addition, tensor product and contraction, for example.\n",
    "\n",
    "**Tensor product is not implemented in PyTorch**.\n",
    "Practical applications reduce to to squeezing dimensions over 2, resulting in a 2-D tensor (or matrix), when multiplication is needed, thus the PyTorch multiplication is actually a matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do tensors multiplication, use ``torch.mm`` or ``torch.matmul`` .\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "Don't confuse ``dot`` and ``mm`` operators, check <a href=\"https://stackoverflow.com/questions/44524901/how-to-do-product-of-matrices-in-pytorch\" class=\"alert-link\">this link.</a>\n",
    " \n",
    "To get element-wise product, use A*B.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [2 x 3], m2: [2 x 3] at /opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/TH/generic/THTensorMath.cpp:752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-545949da22e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# doens't work, do you know why?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [2 x 3], m2: [2 x 3] at /opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/TH/generic/THTensorMath.cpp:752"
     ]
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1,2,3],[4,5,6]]))\n",
    "b = a\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "c = torch.mm(a,b)# doens't work, do you know why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can the tensors a and  b be matrix-multiplied? Why / Why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To matrix-multiply objects, the last dimension of the first object needs to coincide with the first dimension of the 2nd object.\n",
    "If we have two objects with identical dimensionalities, one way to make the multiplication compatible is  to transpose either of those objects. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 32],\n",
      "        [32, 77]])\n",
      "tensor([[17, 22, 27],\n",
      "        [22, 29, 36],\n",
      "        [27, 36, 45]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.mm(a,b.t())\n",
    "d = torch.mm(a.t(),b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Place Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess what is the following code going to print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First multiplication and addition succeeded\n",
      "The result of in-place addition is tensor([[ 2,  4,  6],\n",
      "        [ 8, 10, 12]])\n",
      "Second addition succeeded\n",
      "Second  multiplication failed\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(np.array([[1,2,3],[4,5,6]]))\n",
    "b = a\n",
    "try:\n",
    "    torch.mm(a,b.t())\n",
    "    torch.add(a,b)\n",
    "    print(\"First multiplication and addition succeeded\")\n",
    "except :\n",
    "    print(\"First  multiplication failed\")\n",
    "\n",
    "try :\n",
    "    print(f\"The result of in-place addition is {a.add_(b)}\")\n",
    "    print(\"Second addition succeeded\")\n",
    "    (a.t()).mm_(b)\n",
    "    print(\"Second multiplication succeeded\")\n",
    "except:\n",
    "    print(\"Second  multiplication failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was your guess correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crux lies in the _ meaning: We can often find underscored_versions of methods in PyTorch, which stand for in-place operations. That means that the object on which the operation is called, is changed in the computer memory, without explicitly saving the result.\n",
    "\n",
    "Thus, often a binary operations $$(x , y)  \\rightarrow z$$ that operates on two arguments can be made to be unary,\n",
    "resulting in\n",
    "\n",
    "$$x.method(y) \\rightarrow z$$,\n",
    "\n",
    "operating only on one argument, while the object the method is operating on (in this case ``x``), is meant to be overwritten in the computer memory, since the operation is done in-place.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "    Notice however that multiplication as defined by ``mm`` or ``matmul`` or ``@`` does not have an in-place version, this it is always binary.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Definition\n",
    "[Neural Networklink on Wikipedia](https://en.wikipedia.org/wiki/Neural_network)\n",
    "\n",
    "A neural network is a network or circuit of neurons, or in a modern sense, an artificial neural network, composed of artificial neurons or nodes.  \n",
    "The connections of the biological neuron are modeled as weights denoted by $w$ in the following graph. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed . Finally, an activation function (in the following graph, denoted by $f$) controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be âˆ’1 and 1. It is said that each neuron in the following layer gets the linear combination of activations (referring to the use of $f$ in the image below) of neurons from the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"assets/img/neural_network.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd : Automatic Differentiation\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  For the definition of neural network, please refer to the following link:\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NEURAL NETWORK DEFINITION](hb#Neural-Network-Definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autograd**, as one of the modern automatic differentiation frameworks, lies in the **core of Pytorch**.\n",
    "\n",
    "Thus, it would be a very good idea to [Read more about Autograd](https://pytorch.org/docs/master/notes/autograd.html)\n",
    "\n",
    "Autograd package in PyTorch automates the computation of backward passes in computational graphs.\n",
    "\n",
    "In Autograd: \n",
    "- the forward pass of the neural network will define a computational graph\n",
    "- nodes in the graph will be Tensors\n",
    "- edges are functions producing output Tensors from input Tensors\n",
    "- the backward pass of the neural network is for easy computation of gradients for those tensors  ``x``, for which  ``x.requires_grad``= ``True``, with respect to some scalar.\n",
    "\n",
    "**Thus, to compute gradients of some variables, use functions that allow to pass  ``x.requires_grad``= ``True``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2],requires_grad=True,dtype=torch.float)\n",
    "y = torch.tensor([3],requires_grad=True,dtype=torch.float)\n",
    "z = x + y \n",
    "z.backward()\n",
    "print(f\"Gradient with respect to z is {z.grad}\")\n",
    "print(f\"Gradient with respect to x is {x.grad}\")\n",
    "print(f\"Gradient with respect to y is {y.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw the most basic way to get a derivative or gradient.\n",
    "We cannot compute the gradient of z, because it has not been initialized with the argument requires_grad=True.\n",
    "We can though compute the gradient of x, and since derivative from x w.r.t. x is 1, the result is tensor([1.]), since the chosen data type was floating point number.\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    " Note: Often in neural networks, x and y are symbols used for input or output data and usually we are never required to compute gradients w.r.t. to the data.\n",
    "    \n",
    "The reason is simple:\n",
    "When we have a model, e.g. like a neural network that is a black  box model, the model itself shouldn't have any assumptions or explicit dependencies on the data. It's up to the machine learning engineer to define the model or network structure in a way that the model learns from the data, but the underlying machinery should not hold explicit dependency on the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's take a look at another example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2], requires_grad=True, dtype=torch.float)\n",
    "y = torch.tensor([1, 3], requires_grad=True, dtype=torch.float)\n",
    "print(f\"At the beginning, x is {x}\")\n",
    "print(f\"At the beginning, y is {y}\")\n",
    "\n",
    "x = x ** 2\n",
    "y = y ** 2\n",
    "\n",
    "print(f\"After squaring, x is {x}\")\n",
    "print(f\"After squaring, y is {y}\")\n",
    "\n",
    "x.add_(y)\n",
    "\n",
    "print(f\"After adding y to x in-place, the value of x is {x}\")\n",
    "\n",
    "z = x.sum()\n",
    "print(f\"The sum of the elements in this array is {z}\")\n",
    "z.backward()\n",
    "print(\"Finally, after running the backward step to compute the gradients, we get:\")\n",
    "print(z)\n",
    "# Note that z has no gradient requirement by default, thus z.grad prints None.\n",
    "print(f\"The gradient of z is {z.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the correctness of Autograd Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "# important : every time before generating random numbers, you should set the seed!\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "x = Variable(torch.randn(1,1), requires_grad = True)\n",
    "print(f\"The value sampled from normal distribution gives {x} \\n\")\n",
    "y = 3*x\n",
    "print(f\"When we form a linear function of {x} by multiplying this sample value by 3, we get {y}\\n\")\n",
    "z = y**2 # derivative w.r.t. x is:\n",
    "print(f\"After that we form a quadratic function of y, and at this sample value, it takes a value of {z} \\n\")\n",
    "print(\"Now we are going to register the hooks for each variable \\n\")\n",
    "x.register_hook(print)\n",
    "y.register_hook(print)\n",
    "\n",
    "#z.register_hook(print)\n",
    "z.backward(retain_graph=True) # prints all the gradients needed\n",
    "z2.backward(retain_graph=True) # prints all the gradients needed\n",
    "\n",
    "print(f\"Gradients obtained from the first graph are {z.grad} \\n\")\n",
    "#print(f\"Gradients obtained from the second graph are {z2.grad} \\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have seen that z.grad doesn't print anything, but to see the gradient components, you have to register the hook for that particular variable.\n",
    "\n",
    "**The same example with the gradient conflict:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = Variable(torch.randn(1,1), requires_grad = False)\n",
    "y2 = Variable(3*x,requires_grad=False)\n",
    "y2.register_hook(print)\n",
    "z2 = Variable((y2)**2,requires_grad=True)\n",
    "z2.register_hook(print)\n",
    "z2.backward()\n",
    "print(f\"The value of y is {y}\")\n",
    "print(z2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The z value is {9*1.54**2}\")\n",
    "print(f\"The grad_y(z) is {6*1.54}\")\n",
    "print(f\"The grad_x(z) is {18*1.54}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap : How to properly pass tensors and find their gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "xx = Variable(torch.randn(1,1), requires_grad = True)\n",
    "yy = 3*xx\n",
    "zz = yy**2\n",
    "\n",
    "yy.register_hook(print)\n",
    "zz.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure that the differentiation is working correctly, let us compute the following:\n",
    "$$A(x)  = \\partial_x z(y(x)) = \\partial_x (y^2(x)) = \\partial_x (9x^2) = 18x$$.\n",
    "If $x = -1.5298$, then $$A(x) = 18 \\cdot x = -27.5364 \\approx -27.5356$$ \n",
    "\n",
    "and we see how Pytorch could be used as a symbolic mathematics framework to compute e.g. derivatives, since the chain rule is implemented there internally. With computationally intensive tasks, the effective implementation of automatic differentiation could be a huge benefit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "18*(-1.5298) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could observe that PyTorch's grad isn't really a gradient, because the normally known gradient as  in fact a directional derivative. If we wish to take the derivative from x w.r.t. x, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2,4,5],requires_grad=True,dtype=torch.float)\n",
    "x.register_hook(print)\n",
    "x.backward()\n",
    "print(f\"Gradient with respect to x is {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"error\">\n",
    "\n",
    "RuntimeError: grad can be implicitly created only for scalar outputs\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd Application : Gradient Descent in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to take a look at a basic example, adopted from [Github demo for Autograd](https://github.com/jcjohnson/pytorch-examples#pytorch-autograd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLEASE MAKE SURE THAT log_path variable is initialized properly\n",
    "[in setup](#Setting-Up-Visualization-Platform-on-Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"pip install --upgrade tensorboardX --user \"\n",
    "pw = \"data\"\n",
    "!echo {pw}|  {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "log_path = './runs/gd/'\n",
    "\n",
    "if log_path:\n",
    "    print(\"accessing predefined path\")\n",
    "    writer = SummaryWriter(log_dir=log_path)\n",
    "else :\n",
    "    print(\"using new path set\")\n",
    "    writer = SummaryWriter(log_dir='./runs/gd/')\n",
    "#In addition to SummaryWriter, there are also other writers, please check the manual\n",
    "# https://tensorboardx.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "# !tensorboard --logdir log_path --host localhost --port 8088\n",
    "# you have to execute tensorboard command from another shell, otherwise you cannot proceed with running the notebook\n",
    "# read this : https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Code in file autograd/two_layer_net_autograd.py\n",
    "import torch\n",
    "\n",
    "#device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "device = torch.device('cpu') # Uncomment this to run on CPU\n",
    "\n",
    "# N is batch size;\n",
    "# D_in is input dimension;\n",
    "# H is hidden dimension; \n",
    "#D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 350, 50, 20\n",
    "\n",
    "# input data : batch of 64 times 1000 features\n",
    "# output data : 100 x 10 continues values (real scalars)\n",
    "\n",
    "# Create random Tensors to hold input and outputs\n",
    "x = # generate normally distributed data of dim NxD_in, store it on device, requires_grad = False\n",
    "y = # generate normally distributed data of dim NxD_out, store it on device, requires_grad = False\n",
    "\n",
    "# Create random Tensors for weights; setting requires_grad=True means that we\n",
    "# want to compute gradients for these Tensors during the backward pass.\n",
    "# here the gradient will be computed for the variables that are related to the model learning something new,\n",
    "# i.e. the network weights in this case\n",
    "\n",
    "\n",
    "# WEIGHTS\n",
    "w1 = #generate normally distributed data of dim D_in x H, store it on device, requires_grad = True \n",
    "w2 = #generate normally distributed data of dim H x D_out, store it on device, requires_grad = True \n",
    "\n",
    "# initialize loss value to a high number \n",
    "\n",
    "# initialize arrays errors, w1_array and w2_array to empty lists\n",
    "errors = # write here\n",
    "w1_array =  # write here\n",
    "w2_array =  # write here\n",
    " # set the network learning rate parameter 'learning_rate' to some small number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors. Since w1 and\n",
    "    # w2 have requires_grad=True, operations involving these Tensors will cause\n",
    "    # PyTorch to build a computational graph, allowing automatic computation of\n",
    "    # gradients. Since we are no longer implementing the backward pass by hand we\n",
    "    # don't need to keep references to intermediate values.\n",
    "    # predict the values by multiplying x with weight matrix w1, then apply RELU activation and multiply the result by weight matrix w2\n",
    "    y_pred = # your code here ; the final prediction is given by matrix multiplying the data \n",
    "    #with the two set of weights, making the intermediate values non-negative (RELU activation function)\n",
    "\n",
    "    # calculate the mean squared error (MSE)\n",
    "    error =  # your code here\n",
    "\n",
    "    \n",
    "    writer.add_scalar(tag=\"Last run\",scalar_value= error, global_step = iteration)\n",
    "    writer.add_histogram(\"error distribution\",error)\n",
    "    \n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "   \n",
    "    #error.WHAT_FUNCTION_here ?\n",
    "\n",
    "    # Update weights using gradient descent. For this step we just want to mutate\n",
    "    # the values of w1 and w2 in-place; we don't want to build up a computational\n",
    "    # graph for the update steps, so we use the torch.no_grad() context manager\n",
    "    # to prevent PyTorch from building a computational graph for the updates\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # use w1.grad to update w2 according to the gradient descent formula\n",
    "        # use w2.grad to update w2 according to the gradient descent formula\n",
    "        # also use the learning_rate you set before!\n",
    "        w1 -= # your code here\n",
    "        w2 -= # your code here\n",
    "        \n",
    "    if iteration % 50 == 0:\n",
    "        print(\"Iteration: %d - Error: %.4f\" % (iteration, error))\n",
    "        w1_array.append(w1.cpu().detach().numpy())\n",
    "        w2_array.append(w2.cpu().detach().numpy())\n",
    "        errors.append(error.cpu().detach().numpy())\n",
    "    # Manually zero the gradients after running the backward pass\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()\n",
    "    if loss_value < 1e-6:\n",
    "        print(\"Stopping gradient descent, algorithm converged, MSE loss is smaller than 1E-6\")\n",
    "        break\n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Homework Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     33
    ]
   },
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/tutorial/errors.html#raising-exceptions to read more about Exception handling\n",
    "def location_indicator(tensor_):\n",
    "    indicatorstring = \"CUDA\" if tensor_.device.type == \"cuda\" else \"CPU\"\n",
    "    print(f\"The value of tensor_ is {tensor_} and the tensor location type is {indicatorstring}\")\n",
    "    return indicatorstring\n",
    "\n",
    "def try_adding_block(x,y,only_convert_one=True):\n",
    "    print(f\"x is the following {x}\")\n",
    "    print(f\"y is the following {y}\")\n",
    "    try:\n",
    "        if x.device.type == y.device.type:    \n",
    "            if only_convert_one == False:\n",
    "                z = x.type(torch.DoubleTensor) + y.type(torch.DoubleTensor)\n",
    "                print(\"Adding succeeded, objects are in the same memory type\") \n",
    "            else :\n",
    "                try :\n",
    "                    z = x.type(torch.DoubleTensor) + y\n",
    "                except TypeError:\n",
    "                    print(\"Unhandled error thrown because the tensors are of different type!\")\n",
    "                    raise TypeError(\"Unhandled error thrown because the tensors are of different type!\")\n",
    "\n",
    "                \n",
    "        else :\n",
    "             raise TypeError(\"Adding on different memory banks is not allowed, will result in TypeError!\")\n",
    "            \n",
    "    except TypeError:\n",
    "        print(\"The additives are of different type, addition not implemented for different types of tensors!\")\n",
    "    \n",
    "    else :\n",
    "        print(\"No exception thrown!\")\n",
    "    finally:\n",
    "        print(\"End of the function\")\n",
    "                \n",
    "def try_adding_different_locations(x = torch.ones(3,device=\"cpu\"),\\\n",
    "                                   device = torch.device(\"cuda\"),notboth=True,output_type = \"cpu\"):\n",
    "    \"\"\"\n",
    "    First a tensor x is created for CPU and the default device is set to be CUDA.\n",
    "    Then\n",
    "    \"\"\"\n",
    "    if device :\n",
    "        indicatorstring = location_indicator(tensor_=x)\n",
    "        if indicatorstring == \"CPU\":\n",
    "              x = x.to(\"cuda\", torch.double)     # ``.to`` can also change dtype together!\n",
    "              print(f\"Before the Device type was CPU, but now it is {x.device.type}\")\n",
    "        y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "        print(\"First we will enforce the data type of both tensors, adding is going to work!\")\n",
    "        try_adding_block(x,y,only_convert_one=False) # convert both to the same type, adding works\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        indicatorstring_cuda = location_indicator(tensor_=x)\n",
    "        if indicatorstring_cuda == \"CUDA\":\n",
    "            x = x.to(\"cpu\", torch.double)     # ``.to`` can also change dtype together!\n",
    "            print(f\"Before the Device type was CUDA, but now it is {x.device.type}\")\n",
    "        \n",
    "       \n",
    "        indicatorstring_final = location_indicator(tensor_=x) # here the memory type is CPU for one\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        try_adding_block(x,y,only_convert_one = False) # adding doesn't work, different memory locations\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Now we are enforcing the data type of only one tensor, adding is not going to work!\")\n",
    "        try_adding_block(x,y,only_convert_one = notboth) # converting only one , adding doesnt work\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        # After we convert the Memory type to CUDA for both, adding will work:\n",
    "        x = x.to(\"cuda\", torch.double)\n",
    "        try_adding_block(x,y,only_convert_one = False)\n",
    "\n",
    "    else :\n",
    "        print(\"To run this section, please install CUDA as described in the Setting up Pytorch section\")\n",
    "   \n",
    "    print(\"Program ended!\")\n",
    "\n",
    "try_adding_different_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"assets/img/wikipedia_example_notation.png\")\n",
    "\n",
    "# THIS IS HOW YOU SET UP AN OPTIMIATION PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent in Python :\n",
    "## Effect of Parameters in Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that we have been given a generic two variable polynomial function\n",
    "def two_variable_function(x, y):\n",
    "    z = x**3 + 2*(x*y) + 3*(y**2) \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the global minimum of this function within a specified rectangle from -10 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_grid_values  = [two_variable_function(-10,-10),two_variable_function(-10,10),\\\n",
    "                         two_variable_function(10,-10),two_variable_function(10,10)]\n",
    "local_extrema_values = [two_variable_function(0,0),two_variable_function(6/27,-2/27)]\n",
    "min(boundary_grid_values)\n",
    "#np.min(np.array([boundary_grid_values,two_variable_function(0,0),two_variable_function(6/27,-2/27)]))\n",
    "if (min(boundary_grid_values) == min(min(local_extrema_values),min(boundary_grid_values))) == True:\n",
    "    print(f\"The minimum amongst the evaluated points is {min(boundary_grid_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing this function, we get two stationary points\n",
    "$(x,y) = (0,0)$ and $(x,y) = (6/27,-2/27)$, since the first derivatives give:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols\n",
    "x,y = symbols('x y')\n",
    "# z = x^3 + 2xy + 3y^2\n",
    "z = two_variable_function(x, y)\n",
    "derivatives = z.diff(x,1),z.diff(y,1)\n",
    "print(derivatives)\n",
    "# derivatives\n",
    "# dz/dx = 3*coefficients[0]*x**2 + coefficients[1]*y \n",
    "# dz/dy = coefficients[1]*x + 2*coefficients[2]*y\n",
    "# https://docs.sympy.org/latest/tutorial/calculus.html use that to verify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "startgrid=-10\n",
    "endgrid=10.05\n",
    "a = np.arange(startgrid, endgrid, 0.05)\n",
    "b = np.arange(startgrid, endgrid, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(a, b) # creating the evaluation domain grid.\n",
    "# NB! If the global optimum of the function lies outside the grid, \n",
    "# this global optimum would never be discovered since the cost function would never be evaluated there.\n",
    "\n",
    "z = two_variable_function(x, y)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "z_min, z_max = z.min(),z.max()\n",
    "print(z.min())\n",
    "\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('Objective Function Values HeatMap')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# unravel_index does the inverse. Given a linear index, it computes the corresponding ND index. \n",
    "# Since this depends on the block dimensions, these also have to be passed\n",
    "(x_min_idx,y_min_idx) = np.unravel_index(np.argmin(z), z.shape)\n",
    "\n",
    "print(f\"y minimum location is  {a[x_min_idx]}\")\n",
    "print(f\"x minimum location is  {b[y_min_idx]}\")\n",
    "#l2 = b[y_min_idx]\n",
    "#ax.text(-5, -7.5, l1,fontsize=14)\n",
    "plt.show()\n",
    "#ax.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that the minimum value is -1033, and that this happens in a semiellipse close to the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we get close to -1000 also with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13,
     56
    ]
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "#!yes | conda install -n dl -c conda-forge matplotlib   -- to install matplotlib into conda env dl\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from sympy import *\n",
    "import random\n",
    "\n",
    "# define a 2-variable function z = f(x,y)\n",
    "def two_variable_function(x, y):\n",
    "    z = x**3 + 2*x*y + 3*(y**2) \n",
    "    return z\n",
    "\n",
    "def gradient_descent(x_start, y_start, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Each following step of the gradient descent depends on the result of the previous step.\n",
    "    \"\"\"\n",
    "    # initialize the grid values as empty lists for the variables\n",
    "    \n",
    "    # first run\n",
    "    x = y = z = []\n",
    "    x_old = x_start\n",
    "    y_old = y_start\n",
    "    \n",
    "    x.append(x_old)\n",
    "    y.append(y_old)\n",
    "    z_gd = two_variable_function(x_old, y_old)\n",
    "    z.append(z_gd)\n",
    "    \n",
    "    # further runs\n",
    "\n",
    "    # begin the loops to update x, y and z\n",
    "    for i in range(epochs):\n",
    "        x_gd = x_old - learning_rate*(3*x_old**2 + 2*y_old)\n",
    "        y_gd = y_old - learning_rate*(2*x_old + 6*y_old)\n",
    "        x.append(x_gd)\n",
    "        y.append(y_gd)\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        #print(two_variable_function(x, y))\n",
    "        z_gd = two_variable_function(x_gd, y_gd)\n",
    "        z.append(z_gd)  # appending the values for z\n",
    "        # for the next iteration, the new values will be the old values\n",
    "        x_old = x_gd\n",
    "        y_old = y_gd\n",
    "\n",
    "    return x_gd, y_gd, z_gd\n",
    "\n",
    "\n",
    "####### GIVING THE INITIAL VALUES FOR THE GRADIENT DESCENT\n",
    "\n",
    "xstart = -1\n",
    "ystart = -0.5\n",
    "\n",
    "\n",
    "whatindex = -1\n",
    "def precpr(x,prec=3):\n",
    "    return round(x,prec)\n",
    "\n",
    "lr = np.linspace(0.001,1,7)\n",
    "xs = np.linspace(-9.9,9.9,4)\n",
    "ys = xs\n",
    "idx = 0\n",
    "best_triplet = ''\n",
    "best_loss = 1e6\n",
    "best_z = 1e6\n",
    "best_x = 1e6\n",
    "best_y = 1e6\n",
    "z = two_variable_function(xs,ys)\n",
    "print(f\"Before starting gradient descent, objective function value was: {precpr(two_variable_function(x=xs[0],y=ys[0]))}\")\n",
    "\n",
    "for l in lr:\n",
    "    for xstart in xs:\n",
    "        for ystart in ys:\n",
    "            epochs = random.randint(30,100)\n",
    "            x_gd, y_gd, z_gd = gradient_descent(x_start=xstart, y_start=ystart, learning_rate=l, epochs = epochs)\n",
    "            \n",
    "            #print(\"\\n\")\n",
    "            #print(\"Last value of x is\")\n",
    "            #print(x_gd[-1])\n",
    "            if abs((z_gd)-(-1033.33))<best_loss:\n",
    "                best_loss = abs(z_gd -(-1033.33))\n",
    "                best_triplet = f\"{xstart}_{ystart}_{l}\"\n",
    "                whatindex = idx\n",
    "                best_x = x_gd\n",
    "                best_y = y_gd\n",
    "                best_z = z_gd\n",
    "            print(\"\\n\")\n",
    "            print(f\"Iteration {idx},CONFIGURATION l:{l},xstart:{xstart},ystart:{ystart}\")\n",
    "            print(\"\\n\")\n",
    "            print(f\"After gradient descent of {epochs} epochs, the values are:\")\n",
    "            print(f\"At the optimum, the objective function value is {precpr(best_z)}\")\n",
    "            print(f\"At the optimum, the value of x is {precpr(best_x)} and the value of y is {precpr(best_y)}\")\n",
    "            idx += 1\n",
    "\n",
    "print(f\"The optimal loss was achieved in iteration {whatindex}\")\n",
    "print(f\"The found loss coordinates (x,y) are ({precpr(best_x)},{precpr(best_y)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that sometimes gradient descent might converge to a solution outside the feasible region.\n",
    "This is why in neural networks, it is important to understand whether the optimizing algorithm used considers the problem from unconstrained or constrained optimization context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent : Full Example with Dynamic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def gradient_descent_demo(x_start, y_start, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Each following step of the gradient descent depends on the result of the previous step.\n",
    "    \"\"\"\n",
    "    def two_variable_demo_function(x, y):\n",
    "        #z = -x**4 + 2*(x*y) + 3*(y**2) \n",
    "        z = x**2 + 2*(x*y) + 3*(y**2) \n",
    "\n",
    "        return z\n",
    "    # initialize the grid values as empty lists for the variables\n",
    "    \n",
    "    # first run\n",
    "    x_gd=y_gd = z_gd = []\n",
    "    x_old = x_start\n",
    "    y_old = y_start\n",
    "    \n",
    "    x_gd.append(x_old)\n",
    "    y_gd.append(y_old)\n",
    "    z_gd.append(two_variable_demo_function(x_old, y_old))\n",
    "    \n",
    "    # further runs\n",
    "\n",
    "    # begin the loops to update x, y and z\n",
    "    for i in range(epochs):\n",
    "        x = x_old - learning_rate*(2*x_old+2*y_old)\n",
    "        y = y_old - learning_rate*(2*x_old+9*y_old)\n",
    "        x_gd.append(x)\n",
    "        y_gd.append(y)\n",
    "        z_gd.append(two_variable_demo_function(x, y))  # appending the values for z\n",
    "        # for the next iteration, the new values will be the old values\n",
    "        x_old = x\n",
    "        y_old = y\n",
    "\n",
    "    return x_gd, y_gd, z_gd\n",
    "\n",
    "x_gd, y_gd, z_gd = gradient_descent_demo(x_start=0.5, y_start=0.3, learning_rate=0.02, epochs = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startgrid=-2\n",
    "endgrid=2.05\n",
    "a = np.arange(startgrid, endgrid, 0.05)\n",
    "b = np.arange(startgrid, endgrid, 0.05)\n",
    "\n",
    "x, y = np.meshgrid(a, b) # creating the evaluation domain grid.\n",
    "\n",
    "def two_variable_demo_function(x, y):\n",
    "    z = x**2 + 2*(x*y) + 3*(y**2) \n",
    "    return z\n",
    "z = two_variable_demo_function(x, y)\n",
    "\n",
    "# FIND THE ACTUAL MIN coordinates for x and y:\n",
    "(x_min_idx,y_min_idx) = np.unravel_index(np.argmin(z), z.shape)\n",
    "# Actual minimum coordinate values\n",
    "print(x_min_idx)\n",
    "print(a[x_min_idx])\n",
    "print(b[y_min_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that the global minimum of that convex function in that region is located at $(x,y)=(0,0)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gd, y_gd, z_gd = gradient_descent_demo(x_start=0.5, y_start=0.3, learning_rate=0.14, epochs = 10)\n",
    "\n",
    "############ INITIALIZING THE PLOTTING SYSTEM ###############\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    point.set_data([], [])\n",
    "    value_display.set_text('')\n",
    "\n",
    "    return line, point, value_display\n",
    "\n",
    "def animate(i):\n",
    "    # Animate line\n",
    "    line.set_data(x_gd[:i], y_gd[:i])\n",
    "    \n",
    "    # Animate points\n",
    "    point.set_data(x_gd[i], y_gd[i])\n",
    "\n",
    "    # Animate value display\n",
    "    value_display.set_text('Min = ' + str(z_gd[i]))\n",
    "\n",
    "    return line, point, value_display\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.contour(x, y, z, levels=np.logspace(startgrid, endgrid, 15), cmap='CMRmap')\n",
    "# Plot target (the minimum of the function)\n",
    "\n",
    "# PLOT THE ACTUAL MIN POINT \n",
    "min_point = np.array([0., 0.])\n",
    "min_point_ = min_point[:, np.newaxis]\n",
    "\n",
    "ax1.plot(*min_point_, two_variable_demo_function(*min_point_), 'r*', markersize=10)\n",
    "ax1.set_xlabel(r'x')\n",
    "ax1.set_ylabel(r'y')\n",
    "''' Animation '''\n",
    "# Create animation\n",
    "line, = ax1.plot([], [], 'r', label = 'Gradient Descent on Convex Function', lw = 2.0)\n",
    "point, = ax1.plot([], [], 'bo')\n",
    "value_display = ax1.text(0.02, 0.02, '', transform=ax1.transAxes)\n",
    "\n",
    "ax1.legend(loc = 1)\n",
    "\n",
    "anim = animation.FuncAnimation(fig1, animate, init_func=init,\n",
    "                               frames=len(x_gd), interval=120, \n",
    "                               repeat_delay=60, blit=True)\n",
    "\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have seen, why gradient descent is not the most optimal optimizer:\n",
    "    - Finds local optima, not global. Always think whether the optimization problems is convex or concave.\n",
    "    - Only gradient descent itself means **unconstrained** optimization. If there are constraints to the domain, then gradient descent doesn't follow  those!  If we have a continuous function on some domain, then the boundary values have to be checked because the cost function value at those might be more optial\n",
    "    - The optimization may not converge, it may start oscillating or diverge\n",
    "        - Choice of step size is crucial. Too big step size can result in exploding gradient, too small step size in vanishing gradient\n",
    "    - Using only gradient information, we have only 1st order information about the function. There are 2nd order methods such as L-BFGS, Conjugate gradient and Newton method that have improved convergence properties, but at higher computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Lost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Choosing the right cost function for achieving the desired result is a critical point of machine learning problems. The basic approach, if you do not know exactly what you want out of your method, is to use [Mean Square Error (Wikipedia)](https://en.wikipedia.org/wiki/Mean_squared_error) for regression problems and Percentage of error for classification problems. However, if you want _good_ results out of your method, you need to _define good_, and thus define the adequate cost function. This comes from both domain knowledge (what is your data, what are you trying to achieve), and knowledge of the tools at your disposal. \n",
    "\n",
    "I do not believe I can guide you through the cost functions already implemented in TensorFlow, as I have very little knowledge of the tool, but I can give you an example on how to write and assess different cost functions.\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate the various differences between cost functions, let us use the example of the binary classification problem, where we want, for each sample $x_n$, the class $f(x_n) \\in \\{0,1\\}$.\n",
    "\n",
    "Starting with **computational properties**; how two functions measuring the \"same thing\" could lead to different results. Take the following, simple cost function; the percentage of error. If you have $N$ samples, $f(y_n)$ is the predicted class and $y_n$ the true class, you want to minimize\n",
    "\n",
    "* $\\frac{1}{N} \\sum_n \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{ if } f(x_n) \\not= y_n\\\\\n",
    "0 & \\text{ otherwise}\\\\\n",
    "\\end{array} \\right. = \\sum_n y_n[1-f(x_n)] + [1-y_n]f(x_n)$.\n",
    "\n",
    "This cost function has the benefit of being easily interpretable. However, it is not smooth; if you have only two samples, the function \"jumps\" from 0, to 0.5, to 1. This will lead to inconsistencies if you try to use gradient descent on this function. One way to avoid it is to change the cost function to use probabilities of assignment; $p(y_n = 1 | x_n)$. The function becomes\n",
    "\n",
    "* $\\frac{1}{N} \\sum_n y_n p(y_n = 0 | x_n) + (1 - y_n) p(y_n = 1 | x_n)$.\n",
    "\n",
    "This function is smoother, and will work better with a gradient descent approach. You will get a 'finer' model. However, it has other problem; if you have a sample that is ambiguous, let say that you do not have enough information to say anything better than $p(y_n = 1 | x_n) = 0.5$. Then, using gradient descent on this cost function will lead to a model which increases this probability as much as possible, and thus, maybe, overfit.\n",
    "\n",
    "Another problem of this function is that if $p(y_n = 1 | x_n) = 1$ while $y_n = 0$, you are certain to be right, but you are wrong. In order to avoid this issue, you can take the log of the probability, $\\log p(y_n | x_n)$. As $\\log(0) = \\infty$ and $\\log(1) = 0$, the following function does not have the problem described in the previous paragraph:\n",
    "\n",
    "* $\\frac{1}{N} \\sum_n y_n \\log p(y_n = 0 | x_n) + (1 - y_n) \\log p(y_n = 1 | x_n)$.\n",
    "\n",
    "This should illustrate that in order to optimize the _same thing_, the percentage of error, different definitions might yield different results if they are easier to make sense of, computationally.\n",
    "\n",
    "**It is possible for cost functions $A$ and $B$ to measure the _same concept_, but $A$ might lead your method to better results than $B$.**\n",
    "\n",
    "---\n",
    "In conclusion, defining the cost function is defining the goal of your algorithm. The algorithm defines how to get there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the relation between backpropagation and Auto-differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    When applying backpropagation, Gradient descent calculation should be implemented to find minimum loss or error in each loop, auto differentiation constructs this part in place of you no need to how to implement gradient descent.\n",
    "    Basically backpropagation itself is an optimization technique for neural networks while auto differentiation is a calculus method. When these two method from different field are combined, autograd algorithm is occurred as a result which is better way and easier to implement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tensor_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "720px",
    "left": "1441.41px",
    "top": "238px",
    "width": "352.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "611px",
    "left": "778px",
    "right": "20px",
    "top": "630px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
